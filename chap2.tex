\chapter{Scene Graphs}

\section{Mathematical Description}
We model the geometric state of a scene at a single time point as a \emph{scene graph}, which is a tuple $(G, \Theta, Z)$, where $G = (V, E)$ is a directed tree that encodes the scene graph \emph{structure} and $\Theta$ encodes the scene graph \emph{continuous parameters} and $Z$ encodes the scene graph \emph{discrete parameters}.
Although the framework we present can represent articulated objects, in this paper we only consider scenes involving a set of rigid objects $O$.
The scene graph structure includes a vertex $v_o \in V$ for each object $o \in O$ that represents the 6DoF pose of object $o$, as well as a vertex $r \in V$ that represents the the coordinate frame of the observer.
A directed edge $e = (v_i, v_j) \in E$ between objects $i, j \in O$ encodes that the pose of object $j$ is parametrized \emph{relative to} the pose of object $i$, by parameters $\theta_e$ and $z_e$.
The pose of object $j$ relative to object $i$ is denoted $\Delta x(z_e, \theta_e) \in SE(3)$.
A directed edge $e = (r, v_j) \in E$ from the root to an object $j \in O$ encodes that the pose of object $j$ is not parametrized relative to that of any object, but is instead a full 6DoF pose $\theta_e \in SE(3)$ where $SE(3)$ is the special Euclidean group consisting of all 6DoF poses.
The continuous and discrete parameters of the scene graph consist of the parameters for each edge in the structure ($\Theta := \{\theta_e\}_{e \in E}$ and $Z := \{z_e\}_{e \in E}$).
The set of edges $E$ must \emph{span} the set of vertices $V := \{r\} \cup \{v_o\}_{o \in O}$; that is the scene graph structure $G$ is a \emph{directed spanning tree}.

\subsection{Computing the 6DoF poses of all objects in the scene} \label{6dofCalculation}
Given a scene graph $(G, \Theta, Z)$ the pose $x_i \in SE(3)$ of an object $i \in O$ relative to the observer coordinate frame can be computed by walking path in the tree $G$ from the root vertex $r \in V$ to the vertex $v_i \in V$, and successively computing the pose of each object along the path from the pose of its parent (the set of all such poses is $X := \{x_i\}_{i \in O}$.
That is, given pose $x_u \in SE(3)$ and edge $(u, v) \in E$, the pose $x_v \in SE(3)$ is computed as $x_v := x_u \cdot \Delta x(z_e, \theta_e)$ where $\Delta x(z_e, \theta_e) \in SE(3)$ is the relative pose between vertex $u$ and vertex $v$.
For an edge from the root vertex to an object vertex ($e = (r, v_i)$), $x_u := \mathbf{1}$ (the identity element of $SE(3)$) and $\Delta x(z_e, \theta_e) = \theta_e \in SE(3)$ (note that there are no discrete parameters in this case, so $z_e := ()$).
The functional form of $\Delta x(z_e, \theta_e)$ for an edge $e$ between two objects is discussed below.
While not necessary for the algorithms we explore in this document, we ensure $\Delta x(z_e, \theta_e)$ is a differentiable function of $\theta_e$; this can be used to exploit gradient information in inference programs.

\subsection{Modeling face-to-face contact between two objects}
An edge $(v_i, v_j) \in E$ from object $i$ to object $j$ indicates that the pose of object $j$ is represented relative to the pose of object $i$.
Various types of relative pose parametrizations for two objects are possible; for simplicity we model objects as polyhedra, and only model face-to-face contact between objects.
That is, an edge $e = (v_i, v_j)$ indicates that a face of object $i$ is in flush contact with a face of object $j$.
Since each object has multiple faces, the choice of which pair of faces is in contact is encoded in the discrete parameters $z_e$ for the edge.
Concretely, let $F_i$ and $F_j$ denote the faces of object $i$ and object $j$ respectively
Then, $z_e \in F_i \times F_j$.
The continuous parameters $\theta_e$ for an edge $e$ between two objects is an element of $\mathbb{R}^2 \times [0, 2 \pi)$ that contains two translational degrees of freedom ($s, t \in \mathbb{R}$, for the relative offset of the two faces) and one rotational degree of freedom ($\phi \in [0, 2 \pi)$).
For example, a cuboid object $i \in O$, the set of faces is $F_i = \left\{\mathrm{Top, Bottom, Left, Right, Front, Back}\right\}$.
For an edge $e = (i, j)$ where objects $i, j \in O$ where both objects $i$ and $j$ are cuboids, there are 36 possible values for $z_e$.

\paragraph{Slack variables for face-to-face contact}
We extend the parametrization of face-to-face contact between objects with three additional degrees of freedom of \emph{slack variables}: (i) one degree of freedom that encodes the perpendicular distance ($d \in [0, \infty)$) between the two contact faces, and (ii) two degrees of freedom for relative orientation of the two faces, encoded the surface normal unit vector $\mathbf{n}$ of the child object's face, relative to the parent object's face, which takes values on the sphere $S^2$.
Therefore, $\theta_e \in \mathbb{R}^2 \times [0, 2 \pi) \times [0, \infty) \times S^2$ for an edge $e = (v_i, v_j)$ between two objects $i$ and $j$.
Note that although this edge parametrization uses six degrees of freedom for object-to-object edges like the edge parametrization for edges from the root ($e = (r, v_j)$), the prior distribution on these parameters (described below) encourages object $j$ to be \emph{almost} in face-to-face contact with object $i$; whereas the prior distribution on the pose of object $j$ for an edge of the form $(r, v_j)$ is very different, and is typically a uniform distribution over positions within the scene bounding volume, and a uniform distribution on orientations.

\subsection{A Prior Distribution on Scene Graphs}  % alternative title; representation as a generative program
Various prior distributions on scene graphs are possible.
In our experiments, we use a generic prior distribution on scene graphs over a collection of objects $O$ that factors into two components:
(i) a prior distribution on scene graph structures $G$, denoted $p(G)$, and
(ii) a prior distribution on scene graph parameters $(Z, \Theta)$ given structure, denoted $p(Z, \Theta | G)$.
While uncertainty about the number of objects is possible to represent in our framework and implementation, for simplicity assume that the set of objects is known a-priori, and that there is one vertex for each object, and one vertex representing the observer coordinate frame, so $V$ is fixed a-priori to $\{r\} \cup \{v_o\}_{o \in O}$.
Therefore, $p(G)$ reduces to a prior distribution on edges in the scene graph.
For the prior distribution on structure, we use a uniform distribution on directed trees that are rooted at vertex $r$ and span all $|O| + 1$ vertices in the graph.
This set of directed trees is isomorphic to the set of undirected spanning trees over $|O| + 1$ vertices.
%We use a uniform distribution over forests of fixed size $N$. The structure of a forest of $N$ nodes is isomorphic to that of a spanning tree with $N+1$ nodes, where edges between the additional node and its children in the spanning tree are simply deleted.
Therefore, the prior probability of a graph $G = (V, E)$ is obtained by using Cayley's formula to count the number of undirected spanning trees on $|O| +1$ vertices:
\begin{equation}
    p(G) := p_{\mathrm{unif}(|O|)}(G) := \left\{
    \begin{array}{ll}
    (|O| + 1)^{1 - |O|} & \mbox{if $G$ is a directed spanning tree over vertices $V$ rooted at $r$}\\
    0 & \mbox{otherwise}
    \end{array}
    \right.
\end{equation}
The prior distribution on scene graph parameters factors over the edges in the scene graph:
\begin{equation}
    p(Z, \Theta | G) := \prod_{e \in E} p_e(z_e, \theta_e)
\end{equation}
where $p_e(z_e, \theta_e)$ is a probability distribution on $z_e$ and $\theta_e$ that depends on the two vertices in the edge $e = (u, v)$.
For edges $e = (r, v_j)$ where $j$ is an object, $z_e = ()$ and $p_e(z_e, \theta_e)$ is the uniform distribution on elements of $B \times SO(3)$ where $B$ is the bounding volume of the scene and $SO(3)$ is 3D rotation group (the uniform distribution on $SO(3)$ is given by the Haar measure).
For edges $e = (v_i, v_j)$ where $i$ and $j$ are objects, recall that $z_e \in F_i \times F_j$ and (using the edge parametrization including slack variables) $\theta_e = (s, t, \phi, d, \alpha_1, \alpha_2) \in \mathbb{R}^2 \times [0, 2 \pi) \times [0, \infty) \times [0, 2 \pi)^2$.
The prior distribution on edge parameters is:
\begin{equation}
    p_e(z_e, \theta_e) := \frac{1}{|F_i| |F_j|}
    \cdot p_{\mathrm{norm}(0, \sigma)}(s) \cdot p_{\mathrm{norm}(0, \sigma)}(t)
    \cdot \frac{1}{2 \pi}
    \cdot p_{\mathrm{exp}(\beta)}(d)
    \cdot \frac{1}{2 \pi}
    \cdot \frac{1}{2 \pi}
\end{equation}
(where $p_{\mathrm{norm}}$ and $p_{\mathrm{exp}}$ are the normal and exponential distribution density functions, respectively).

\subsection{Probabilistic Dynamics on Scene Graphs}
We build temporal models of scene geometry based on Markov chains of scene graphs $\{(G_t, \Theta_t, Z_t)\}_{t=1}^T$, where $t$ indexes time, with transitions $p(G_t, \Theta_t, Z_t | G_{t-1}, \Theta_{t-1}, Z_{t-1})$.
We factor the dynamics model on scene graphs decomposes into a dynamics model on scene graph structure, and a dynamics on parameters:
\begin{align}
    p(G_t, \Theta_t, Z_t | G_{t-1}, \Theta_{t-1}, Z_{t-1}) :=
        p(G_t | G_{t-1})
        \cdot p(Z_t, \Theta_t, | Z_{t-1}, \Theta_{t-1}, G_{t-1}, G_t)
\end{align}
The dynamics on graph structure is based on a mixture of a random walk on structures (to capture incremental changes to the structure of a scene that often occur) and a uniform distribution on structures (to model sudden unexpected changes in structure):
\begin{equation}
    p(G_t | G_{t-1}) :=  0.9 \cdot p_{\mathrm{walk}}(G_t | G_{t-1}) + 0.1 \cdot p_{\mathrm{unif}(|O|)}(G_t)
\end{equation}
where $p_{\mathrm{walk}}(G' | G)$ is the distribution on graph structures induced by a sampling process in which one vertex in the undirected spanning tree is selected at random, severed from the tree, and grafted back onto the graph at a uniformly chosen vertex, subject to the condition that the resulting graph is a spanning tree.
% TODO show a graphic of this..
Recall that since the tree contains the root node $r$, this process can change the edge type $(u, v_j)$ for an object $i$ from $(r, v_j)$ (representing independent 6DoF pose) to $(v_i, v_j)$ (representing flush contact pose with another object $v_i$.
The dynamics on parameters factor according to edges in the graph:
\begin{equation}
    p(Z_t, \Theta_t | Z_{t-1}, \Theta_{t-1}, G_{t-1}, G_t) := \prod_{e \in E} p_e(z_e, \theta_e | G_t, G_{t-1}, {z_{t-1}}_e, {\theta_{t-1}}_e)
\end{equation}
If an edge $e$ is present in both $G_t$ and $G_{t-1}$, then this distribution is a mixture of a random walk and a uniform distribution.
If an edge $e$ in $G_t$ was not present in $G_{t-1}$, then this distribution is a uniform distribution.

\subsection{Robust Pose Likelihood for Modeling Noisy Neural Detections}
In order to model noisy neural network detections for each object $o \in O$, we introduce a likelihood over observed object pose detections $Y := \{y_o\}_{o \in O} = \{(y_o^\mathrm{pos}, y_o^\mathrm{rot})\}_{o \in O}$.
The likelihood consists of two components in a mixture model:
(i) a uniform distribution over a finite cuboid region in 3D space, and
(ii) a product of a diagonal multivariate Gaussian over object positions, and a von Mises--Fisher distribution over rotations, represented as unit vectors in $S^3$ (quaternions).
The first component represents the possibility of outlier neural ``flicker'', where objects may be properly recognized as being in the scene, but are very poorly localized.
The second component represents where the inlier cases where the neural detector roughly captures the correct location of the object in the scene, with small local inaccuracies.
\begin{equation} \label{eq:noisy-pose-likelihood}
  p(Y | X, \sigma, \kappa) =
  \prod_{o \in O}
    \left(\alpha \cdot \frac{1}{LWH} +
    (1 - \alpha) \cdot \mathcal{N}\left(y_o^\mathrm{pos}; x_o^\mathrm{pos}, \sigma\right) \cdot
    \mathrm{VMF}(y_o^\mathrm{rot}; x_o^\mathrm{rot}, \kappa)\right)
\end{equation}


\subsection{Reversible Jump MCMC for Structure Inference}
When considering how to infer the posterior distribution over scene graph structure $G$, we might take inspiration from our graph random walk distribution $p_\mathrm{walk}(G_t|G_{t_1})$ to build an incremental graph modification kernel that proposes small changes to the structure.
However, when changing an edge type from $e \to e'$, we also induce a new set of parameters $\theta_{e'}$ that must be simultaneously proposed or resimulated.
Ultimately these two parameterizations are just different ways to express identical absolute poses $x_j = x'_j$, as either relative to another object, or to the observer coordinate frame.

Reversible jump MCMC (RJMCMC) is a generalization of the MH algorithm that allows moves between models with different state spaces, while reusing information in the different model latents to accelerate inference.
We provide the formulation of RJMCMC here without proof of asymptotic correctness; for a full derivation see Green et. al~\cite{green2009reversible}.
Define a set of models $k \in \mathcal{K}$, each with latent variables $\theta_k \in \R^{N_k}$ and joint density $p_k(k,\theta_k,\mathcal{D})$, as well as a set of reversible jump moves $m \in \mathcal{M}$, each of which switches between two models $k,k' \in \mathcal{K}$.
For each model, we have a distribution over possible moves $q_k(m)$ with support over a subset of $\mathcal{M}$.
Each reversible jump move from $k \to k'$ proposes a value for $\theta_{k'}$ given $\theta_{k}$, using a differentiable bijection $f$.
However, in general $N_{k} \neq N_{k'}$, which prevents us from making a bijection between these two spaces.
To ameliorate this, we pad the latent spaces of both models with additional auxiliary randomness.
In the forward direction ($k \to k'$), we sample $u \sample q(\cdot)$ where $u \in \R^{D_{k}}$, and in the backward direction ($k' \to k$), we sample $u \sample q'(\cdot)$ where $u \in \R^{D_{k'}}$; we additionally require $N_{k} + D_{k} = N_{k'} + D_{k'}$ such that we can define a bijection between our two extended spaces.
We then let the bijection be between these two extended state spaces; the forward move then proposes new values $(\theta_{k'}, u') = f(\theta_{k}, u)$, which we accept with probability $\min\{1,\alpha\}$, where
\begin{equation}
  \alpha = \frac{p_{k'}(k',\theta_{k'},\mathcal{D})q(u)q_{k'}(m)}{p_{k}(k,\theta_{k},\mathcal{D})q'(u')q_k(m)} \cdot \abs{\det J_f}
\end{equation}

Because our different parameterizations ultimately represent the same absolute poses, RJMCMC offers a way to reuse our inferred continuous parameters $\theta_e$ to efficiently propose values for $\theta_{e'}$.
Explicitly, we define a class of reversible jump moves parameterized by $j \in V$ that determines which node will have a new parent proposed.
If $j$ is floating in $G = (V,E)$, then the models reachable have structure $(V, E \setminus \{(r,j)\} \cup \{(i,j)\})$, and discrete parameter $z_{(i,j)} = (f_i, f_j)$.
The corresponding moves are sampled from the distribution $m_\mathrm{sliding} = (i, f_i, f_j) \sample q_\mathrm{floating}(\cdot, \cdot, \cdot)$.
Inversely, if $j$ is sliding, then the only model reachable has structure $(V, E \setminus \{(i,j)\} \cup \{(r,j)\})$.
We call the move corresponding to this $m_\mathrm{floating}$, and $q_\mathrm{sliding}(m_\mathrm{floating}) = 1$.
The slack terms mean both floating and sliding continuous parameters have 6DoF, thereby precluding the need for sampling auxiliary continuous random variables; this is the main motivation for explicitly modeling a slack term.

The final component are the bijections.
All sliding to floating moves have the bijection $f_{m_\mathrm{floating}}(G, \Theta, Z) = (G', \Theta', Z')$, where $E' = E \setminus \{(i,j)\} \cup \{(r,j)\})$, $z'_{(i,j)} = ()$, and $\theta_{(i,j)}$ is calculated using the method described in section~\ref{6dofCalculation}.
All floating to sliding moves inversely have the bijection $f_{(i, f_i, f_j)}(G', \Theta', Z') = (G, \Theta, Z)$, where $E = E' \setminus \{(r,j)\} \cup \{(i,j)\})$, $z'_{(i,j)} = (f_i, f_j)$, and $\theta_{(i,j)}$ is calculated as the sliding continuous parameters given contacting faces $f_i, f_j$ and parent pose $x_i$, such that the absolute pose $x'_j = x_j$.

The position parameterizations in the floating and sliding cases are both $\R^3$, and thus the Jacobian correction is simply $1$ for these subspaces.
Orientations are slightly more complex; in the floating case, the orientation is represented as a unit vector in $S^3$ (which has a double-covering surjective homomorphism to the rotation group SO(3)).
In the sliding case, the orientation is represented as the Hopf fibration, which has local product structure $S^2 \times S^1$.
This local topology means our Jacobian correction for the transformation between these spaces is constant.
\todo[Ask Marco how he got the Jacobian correction]
\begin{equation}
  \abs{\det J_{f_{m_\mathrm{sliding}}}} = \abs{\det J_{f_{m_\mathrm{floating}}}}^{-1} = 4
\end{equation}

Gen automatically calculates the acceptance ratio for RJMCMC and makes appropriate MH moves, given the involutions and associated Jacobian corrections.


%%%% begin sampling notation  - to go in an floating algorithm gbox showing probabilistic pseudocode 
\lstset{language=julia}
\lstset{style=Gen}

\begin{figure}[p]
\centering
\begin{subfigure}{\textwidth}
\begin{lstlisting}
@gen function model(T::Int)
    latent_gs = []
    for t = 1:T
        # structure and parameter dynamics
        if t == 1
            structure ~ UniformDiForest(N)
            params ~ params_init(structure)
        else
            (prev_structure, prev_params) = decompose(gs[t-1])
            structure ~ StructureTransition(prev_structure)
            params ~ params_dynamics(structure, prev_params)
        end

        # observation
        latent_g = SceneGraph(structure, params)
        obs ~ noise_model(latent_g)
        push!(latent_gs, latent_g)
    end
    return latent_gs
end
\end{lstlisting}
\subcaption{Top-level scene graph model}
\end{subfigure}

\begin{subfigure}{\textwidth}
\begin{lstlisting}
@gen function init_params(structure::SimpleDiGraph)
    params = []
    for i in vertices(structure)
        if isFloating(structure, i)
            xs = {i} ~ init_floating_pose()
        else
            xs = {i} ~ init_sliding_pose(parent(structure, i))
        end
        push!(params, xs)
    end
    return params
end
\end{lstlisting}
\subcaption{Parameter initialization}
\end{subfigure}

\begin{subfigure}{\textwidth}
\begin{lstlisting}
@gen function params_dynamics(structure, prev_params, hypers)
    new_params = []
    for i in vertices(structure)
        if isFloating(structure, i)
            new_xs = {i} ~ floating_pose_dynamics(prev_params[i])
        else
            new_xs = {i} ~ sliding_pose_dynamics(prev_params[i], parent(structure, i))
        end
        push!(new_params, new_xs)
    end
    return new_params
end
\end{lstlisting}
\subcaption{Parameter dynamics}
\end{subfigure}

\begin{subfigure}{\textwidth}
\begin{lstlisting}
RobustNoisyPoseLikelihood = Mixture([GaussianVMF, UniformPose])

@gen function noise_model(g)
    # use Mixture to construct a mixture of uniform and gaussian vmf with prob_outlier of being uniform
    observed_poses = []
    for i in vertices(g)
        latent_pose = get_floating_pose(g, i)  # get 6DoF pose for object i
        observed_pose = {i} ~ RobustNoisyPoseLikelihood([1 - p_outlier, p_outlier],
                                                        [(latent_pose, inlier_pos_stdev, inlier_rot_conc),
                                                        (outlier_bounds,)])
        push!(observed_poses, observed_pose)
    end
    return observed_poses
end
\end{lstlisting}
\subcaption{Noisy observational model}
\end{subfigure}

\caption{Probabilistic pseudocode for an example dynamic scene graph model}
\end{figure}

\section{Example Applications of Scene Graph Models}

\todo

\subsection{YCB Objects on a synthetic tabletop}

\todo

\subsection{Real YCB objects on a physical tabletop}

\todo

\subsection{Simulated objects in AI2Thor}

\todo
